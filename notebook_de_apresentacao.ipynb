{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "notebook de apresentacao.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOaDAC3xsBc/3OBxbq3na/C",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/matheus97eng/desafio_solvimm/blob/main/notebook_de_apresentacao.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3rxknMGz5h9B"
      },
      "source": [
        "importando bibliotecas"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "--p0-yqB5hgH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1c683cf2-35e7-45a6-f18b-3edc3558a927"
      },
      "source": [
        "import pandas as pd\n",
        "import string, re, nltk\n",
        "#from nltk import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "nltk.download('stopwords')      # obtem as stopwords"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2YMITy_gz2ug"
      },
      "source": [
        "- pandas - manipula√ß√£o de dataframes\n",
        "- nltk.word_tokenize - \n",
        "- nltk.corpus.stopwords - lista de palavras consideradas \"stopwords\"\n",
        "- string - manipula√ß√£o de strings\n",
        "- re - biblioteca python para opera√ß√£o de strings com codifica√ß√£o. No caso iremos trabalhar com a codifica√ß√£o dos emojis.\n",
        "- da biblioteca sklearn:\n",
        "    - MultinomialMB - algoritmo de Naive Beyes do tipo multinominal, o mais indicado para multiclassifica√ß√£o\n",
        "    - train_test_split - divide os dados em treino e teste\n",
        "    - accuracy_score - m√©todo utilizado para validar o modelo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "36kzk5Ol48OO"
      },
      "source": [
        "## obten√ß√£o dos dados e tratamento\n",
        "\n",
        "Os dados foram fornecidos pela empresa SOLVIMM, que prop√¥s o desafio. Eles correspondem a uma base de dados de produtos cadastrados pela empresa \"Ponto Quente\"."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 442
        },
        "id": "RaJgpe5x5XdG",
        "outputId": "b56afc68-ed69-4ae7-8bb0-549818f3330d"
      },
      "source": [
        "arq = 'https://github.com/matheus97eng/desafio_solvimm/blob/main/data/reviews.tsv?raw=true' # reposit√≥rio do github\n",
        "df_original = pd.read_csv(arq, sep='\\t')\n",
        "print(df_original.shape)\n",
        "df_original.head()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(170583, 16)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>marketplace</th>\n",
              "      <th>customer_id</th>\n",
              "      <th>review_id</th>\n",
              "      <th>product_id</th>\n",
              "      <th>product_parent</th>\n",
              "      <th>product_title</th>\n",
              "      <th>star_rating</th>\n",
              "      <th>helpful_votes</th>\n",
              "      <th>total_votes</th>\n",
              "      <th>vine</th>\n",
              "      <th>verified_purchase</th>\n",
              "      <th>review_headline</th>\n",
              "      <th>review_body</th>\n",
              "      <th>review_date</th>\n",
              "      <th>product_category</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>762868</td>\n",
              "      <td>UK</td>\n",
              "      <td>29723892</td>\n",
              "      <td>R3VNENIATVV8QE</td>\n",
              "      <td>B00NOPQU2K</td>\n",
              "      <td>627793267</td>\n",
              "      <td>The Girl on the Train</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>N</td>\n",
              "      <td>N</td>\n",
              "      <td>Gripping you right where it matters</td>\n",
              "      <td>I know to say a story is &amp;#34;gripping&amp;#34; is...</td>\n",
              "      <td>2015-04-27</td>\n",
              "      <td>Digital_Ebook_Purchase</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1284183</td>\n",
              "      <td>UK</td>\n",
              "      <td>41072087</td>\n",
              "      <td>R2U3LV67N99770</td>\n",
              "      <td>B0013F2LSK</td>\n",
              "      <td>13214624</td>\n",
              "      <td>11</td>\n",
              "      <td>5</td>\n",
              "      <td>2</td>\n",
              "      <td>5</td>\n",
              "      <td>N</td>\n",
              "      <td>Y</td>\n",
              "      <td>The Best of Me</td>\n",
              "      <td>This album is totally fantastic, a great mix o...</td>\n",
              "      <td>2008-03-18</td>\n",
              "      <td>Music</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1599315</td>\n",
              "      <td>UK</td>\n",
              "      <td>49938094</td>\n",
              "      <td>R3RO94POCHNI9V</td>\n",
              "      <td>B005CVWWJY</td>\n",
              "      <td>769273676</td>\n",
              "      <td>Ready Player One</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>N</td>\n",
              "      <td>Y</td>\n",
              "      <td>superb</td>\n",
              "      <td>Enjoyed every second of this book.  It took me...</td>\n",
              "      <td>2014-08-28</td>\n",
              "      <td>Digital_Ebook_Purchase</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>204782</td>\n",
              "      <td>UK</td>\n",
              "      <td>14398213</td>\n",
              "      <td>R3S2BB5SBWBC1</td>\n",
              "      <td>B00008AWV3</td>\n",
              "      <td>841759677</td>\n",
              "      <td>The Four Feathers [DVD] [1939]</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>N</td>\n",
              "      <td>Y</td>\n",
              "      <td>Sweeping, authentic historic drama</td>\n",
              "      <td>I loved the historic scenes---the English coun...</td>\n",
              "      <td>2013-12-27</td>\n",
              "      <td>Video DVD</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>352938</td>\n",
              "      <td>UK</td>\n",
              "      <td>20140500</td>\n",
              "      <td>R27E2PNXJSWJIN</td>\n",
              "      <td>B00FAXJHCY</td>\n",
              "      <td>803172158</td>\n",
              "      <td>The Martian</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>N</td>\n",
              "      <td>Y</td>\n",
              "      <td>... a few pages to get through it but a good b...</td>\n",
              "      <td>May have skipped a few pages to get through it...</td>\n",
              "      <td>2015-06-06</td>\n",
              "      <td>Digital_Ebook_Purchase</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Unnamed: 0 marketplace  ...  review_date        product_category\n",
              "0      762868          UK  ...   2015-04-27  Digital_Ebook_Purchase\n",
              "1     1284183          UK  ...   2008-03-18                   Music\n",
              "2     1599315          UK  ...   2014-08-28  Digital_Ebook_Purchase\n",
              "3      204782          UK  ...   2013-12-27               Video DVD\n",
              "4      352938          UK  ...   2015-06-06  Digital_Ebook_Purchase\n",
              "\n",
              "[5 rows x 16 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c6d4bKjBqB6p"
      },
      "source": [
        "### Informa√ß√µes das features, exclus√£o de dados nulos e explica√ß√£o do modelo:\n",
        "\n",
        "Vamos obter uma vis√£o geral das features em quest√£o."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 420
        },
        "id": "KI6zuFATqBUZ",
        "outputId": "b200cb6b-5daf-4ed2-bf56-21dbaa9175b5"
      },
      "source": [
        "display(df_original.info())"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 170583 entries, 0 to 170582\n",
            "Data columns (total 16 columns):\n",
            " #   Column             Non-Null Count   Dtype \n",
            "---  ------             --------------   ----- \n",
            " 0   Unnamed: 0         170583 non-null  int64 \n",
            " 1   marketplace        170583 non-null  object\n",
            " 2   customer_id        170583 non-null  int64 \n",
            " 3   review_id          170583 non-null  object\n",
            " 4   product_id         170583 non-null  object\n",
            " 5   product_parent     170583 non-null  int64 \n",
            " 6   product_title      170583 non-null  object\n",
            " 7   star_rating        170583 non-null  int64 \n",
            " 8   helpful_votes      170583 non-null  int64 \n",
            " 9   total_votes        170583 non-null  int64 \n",
            " 10  vine               170583 non-null  object\n",
            " 11  verified_purchase  170583 non-null  object\n",
            " 12  review_headline    170583 non-null  object\n",
            " 13  review_body        170582 non-null  object\n",
            " 14  review_date        170578 non-null  object\n",
            " 15  product_category   170583 non-null  object\n",
            "dtypes: int64(6), object(10)\n",
            "memory usage: 20.8+ MB\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "None"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AAxkps_W2GIo"
      },
      "source": [
        "O desafio nos pede para classificar os produtos somente de acordo com os reviews feitos pelos clientes. Esclarecido isso, n√£o precisamos nos preocupar com outras features, a n√£o ser: `review_headline`, que √© o t√≠tulo da avalia√ß√£o, `review_body`, que √© a avalia√ß√£o em si e por fim, `product_category`, que √© a categoriza√ß√£o corrigida do produto. Aqui n√£o consideraremos relevante a data de postagem do review, nem o ID do review.\n",
        "\n",
        "Dado que as features `review_headline` e `product_category` s√£o todas texto (do tipo caracter), e por se tratar de um problema de classifica√ß√£o (identificar qual a classe que o produto pertence), precisamos de um modelo que utilize NPL (Natural Language Processing). Ser√° escolhido o algoritmo de [Nave Beyes](https://www.analyticsvidhya.com/blog/2017/09/naive-bayes-explained/), pois √© um algoritmo de f√°cil aplica√ß√£o com python e sklearn, tem uma boa resposta dado uma quantidade pequena de dados e n√£o √© um algoritmo pesado. \n",
        "\n",
        "Uma desvantagem desse modelo √© que ele n√£o considera a sem√¢ntica do texto. Por exemplo, ao olhar para a frase \"meus dedos ficaram muito apertados quando eu testei na corrida\". Analisando o contexto, poder√≠amos identificar que o produto se trata provavelmente de um t√™nis. Mas o Nave Beyes analisa palavra por palavra, separadamente, o que tornaria mais dif√≠cil a identifica√ß√£o, nesse exemplo dado.\n",
        "\n",
        "Explicando de uma forma n√£o formal, o algoritmo de Nave Beyes trabalha calculando qual √© a probabilidade de um produto ser da classe \"X\" sendo que no review desse produto encontramos certas \"palavras-chave\". Treinando o modelo, ele consegue identificar, por exemplo que, se no review aparecer a palavra \"bola\", √© mais prov√°vel que o produto seja da categoria \"esportes\". Com as informa√ß√µes da base de dados, o algoritmo estar√° treinado e validado para classificar outros produtos, fora da base de dados preparada pelo time de dados da \"Ponto Quente\". \n",
        "\n",
        "No entanto, antes de modelar nosso problema, precisamos tratar os nossos dados.\n",
        "Executando `df_original.info()` j√° vemos que a feature `review_body` possui uma linha com dado nulo. Isso porque vemos 170582 dados n√£o nulos nessa coluna, enquanto que a nossa base de dados possui 170583 linhas. Vamos optar por excluir toda a linha que cont√©m esse dado nulo, j√° que atrapalhar√° no desenvolvimento do modelo e se trata apenas de um produto."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "68Co4Ztj2Frg"
      },
      "source": [
        "excluir = df_original[df_original['review_body'].isnull()].index\n",
        "df_tratado = df_original.drop(excluir).reset_index()"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oq_qJkCiv54f"
      },
      "source": [
        "### Tipos de classifica√ß√£o\n",
        "\n",
        "√â importante tamb√©m olharmos para os tipos de classifica√ß√£o de produtos que a empresa tem. Na base fornecida, foram identificados 32 classes. √â essencial entender que o modelo a ser treinado **n√£o identificar√° classes de produtos que n√£o est√£o na base de dados**. Desse modo, se a empresa quisesse identificar um produto como classe \"carro\" ou n√£o, teria que acrescentar √† base de dados v√°rios produtos da categoria \"carro\".\n",
        "\n",
        "O modelo de machine learning n√£o consegue interpretar dados do tipo string. Portanto, precisamos alterar os dados da coluna alvo `product_category`, fazendo uma tokeriza√ß√£o simples, em outras palavras, substituindo as palavras por n√∫meros."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7_XSlsgvuKYQ",
        "outputId": "763d34b8-3615-4220-acae-78489a90c552"
      },
      "source": [
        "df_tratado['num_category'] = df_tratado['product_category'].map({'Digital_Ebook_Purchase':0, \n",
        "       'Music':1, 'Video DVD':2, 'Mobile_Apps':3, 'Books':4, 'Electronics':5, \n",
        "       'Toys':6, 'Video Games':7, 'Digital_Video_Download':8, 'Digital_Music_Purchase':9, \n",
        "       'PC':10, 'Camera':11, 'Baby':12, 'Wireless':13, 'Home Entertainment':14, 'Sports':15,\n",
        "       'Musical Instruments':16, 'Lawn and Garden':17, 'Home Improvement':18, 'Home':19, \n",
        "       'Watches':20, 'Video':21, 'Shoes':22, 'Office Products':23, 'Automotive':24, \n",
        "       'Health & Personal Care':25, 'Personal_Care_Appliances':26, 'Software':27, \n",
        "       'Kitchen':28, 'Luggage':29, 'Pet Products':30, 'Beauty':31})"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0         0\n",
              "1         1\n",
              "2         0\n",
              "3         2\n",
              "4         0\n",
              "         ..\n",
              "170577    4\n",
              "170578    2\n",
              "170579    1\n",
              "170580    1\n",
              "170581    3\n",
              "Name: num_category, Length: 170582, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IzJxBq6Uv3Uy"
      },
      "source": [
        "### Features de review dos clientes\n",
        "\n",
        "H√° duas colunas no dataframe com o conte√∫do de avalia√ß√µes dos clientes: `review_headline`, que cont√©m o t√≠tulo da avalia√ß√£o, e `revew_body`, que cont√©m o corpo do review.\n",
        "\n",
        "Inicialmente, vamos juntar todas as palavras dessas duas features em uma coluna apenas, j√° que o contexto do texto n√£o importa no modelo de Naive Beyes. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lMbsE_fEv24c"
      },
      "source": [
        "chars = [(df_tratado['review_headline'].iloc[i] + ' ' + df_tratado['review_body'].iloc[i])\n",
        "         for i in df_tratado.index.to_list()]\n",
        "df_tratado['review_total'] = chars"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fh71j-vK1HQ4",
        "outputId": "40943167-d88b-4b8b-c210-b16accb87dfc"
      },
      "source": [
        "emoji_pattern = re.compile(\"[\"\n",
        "        u\"\\U0001F300-\\U0001F5FF\"  # s√≠mbolos\n",
        "        u\"\\U0001F680-\\U0001F6FF\"  # transporte e s√≠mbolos de mapa\n",
        "        u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
        "        u\"\\U0000231A-\\U000023F3\"  # rel√≥gios e setas\n",
        "        u\"\\U000026A1-\\U000026BE\"  # rel√¢mpago, cores e bolas de esportes\n",
        "        u\"\\U00002753-\\U00002757\"  # pontua√ß√£o\n",
        "        u\"\\U00002B50\"             # estrela\n",
        "        u\"\\U0001F32D-\\U0001F37F\"  # comidas\n",
        "        u\"\\U0001F3A0-\\U0001F3D3\"  # esportes\n",
        "        u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
        "        u\"\\U0001F910-\\U0001F93E\"  # mais emoticons e emojis de esportes\n",
        "                           \"]+\", flags=re.UNICODE)\n",
        "emoji_pattern"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "re.compile(r'[üåÄ-üóøüöÄ-\\U0001f6ff\\U0001f1e0-üáø‚åö-‚è≥‚ö°-‚öæ‚ùì-‚ùó‚≠êüå≠-üçøüé†-üèìüòÄ-üôèü§ê-ü§æ]+', re.UNICODE)"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oNutsFY8Adi3"
      },
      "source": [
        "#def clean_text()\n",
        "\n",
        "col_corrigida = []\n",
        "char_excluir = string.punctuation + string.digits\n",
        "\n",
        "for row in df_tratado.index.to_list():\n",
        "    temp = [char for char in df_tratado['review_total'].iloc[row] if char not in char_excluir]\n",
        "    text = ''.join(temp).lower()\n",
        "    text = emoji_pattern.sub(r'', text)\n",
        "    for word in stopwords.words('english'):\n",
        "        text.replace(word, '')\n",
        "    col_corrigida.append(text)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kTVAk4IABWjm"
      },
      "source": [
        "df_tratado['review_total'] = col_corrigida\n",
        "df_tratado['review_total']\n",
        "\n",
        "df_ML = df_tratado[['review_total', 'num_category']]"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OrZ7Rhq4xyCg"
      },
      "source": [
        "## prepara√ß√£o final para aplicar o algoritmo:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SLMjDh0B4Dz-",
        "outputId": "ac4ea45f-6eeb-491c-cc41-a84984914998"
      },
      "source": [
        "x_train, x_test, y_train, y_test = train_test_split(df_ML['review_total'], df_ML['num_category'], random_state=50)\n",
        "\n",
        "vect = CountVectorizer(ngram_range=(2,2))\n",
        "X_train = vect.fit_transform(x_train)\n",
        "X_test = vect.transform(x_test)\n",
        "\n",
        "mnb = MultinomialNB(alpha =0.2)\n",
        "\n",
        "mnb.fit(X_train,y_train)\n",
        "\n",
        "result= mnb.predict(X_test)\n",
        "print(result)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2 2 3 ... 2 4 1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dXHyItV15ju1",
        "outputId": "ffe2cc63-00a0-4bdc-adc2-b9d1d72d8ae4"
      },
      "source": [
        "accuracy_score(result,y_test)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7324250808985603"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    }
  ]
}