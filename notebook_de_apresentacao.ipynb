{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "notebook_de_apresentacao.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/matheus97eng/desafio_solvimm/blob/main/notebook_de_apresentacao.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FQPGpVufKATI"
      },
      "source": [
        "## Apresentação do problema\n",
        "\n",
        "O problema trabalhado neste notebook se trata de um desafio proposto em um processo seletivo. O desafio é descrito a seguir:\n",
        "\n",
        "A empresa \"Ponto Quente\" está enfrentando um problema no seu banco de dados. De alguma forma, seus produtos foram categorizados de forma errada e isso precisa ser corrigido. O time de inteligência de dados da empresa conseguiu montar um dataset contendo alguns produtos com a classificação correta. Nesse dataset, encontramos várias informações sobre o produto, inclusive os reviews dos clientes.\n",
        "\n",
        "A empresa \"Ponto Quente\" deseja um modelo de machine learning que seja capaz de categorizar automaticamente os seus produtos, baseado nas informações dos reviews dos clientes. Mais especificamente, a empresa quer um programa que recebe o modelo treinado junto com um dataframe a ser categorizado. Este dataframe não pode possuir a coluna `product_category`, que é a coluna que fornece a informação da categoria dos produtos. O programa a ser desenvlvido deve retornar o mesmo dataframe de entrada, mas agora com a coluna `product_category`, com as classificações previstas pelo modelo.\n",
        "\n",
        "Para resolver esse problema, foi utilizado o algoritmo de [Naive Beyes](https://www.analyticsvidhya.com/blog/2017/09/naive-bayes-explained/), do tipo Multinomial, que obteve uma acurácia de aproximadamente 73,24%.\n",
        "\n",
        "O tratamento dos dados, preparação, treinamento e validação do modelo foi toda baseada nesses dois notebooks:\n",
        "\n",
        "+ https://github.com/AarohiSingla/Multinomial-Naive-Bayes/blob/master/news_classifier_unseen_input.ipynb\n",
        "+ https://github.com/AarohiSingla/Multinomial-Naive-Bayes/blob/master/youtube_multinomial_naive_bayes.ipynb\n",
        "\n",
        "Outras consultas foram feitas na documentação das bibliotecas e, sobre remoção de emojis, foi consultado essa [dúvida do stackoverflow](https://stackoverflow.com/questions/33404752/removing-emojis-from-a-string-in-python)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3rxknMGz5h9B"
      },
      "source": [
        "## importando bibliotecas\n",
        "\n",
        "No próximo código importamos as bibliotecas e métodos utilizados para resolução do desafio. Cada uma delas será descrita abaixo também."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "--p0-yqB5hgH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "084dd7c9-029b-4b60-a189-2ec32f2fea8b"
      },
      "source": [
        "import pandas as pd\n",
        "import string, re, nltk\n",
        "#from nltk import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "nltk.download('stopwords')      # obtem as stopwords"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2YMITy_gz2ug"
      },
      "source": [
        "- pandas - manipulação de dataframes\n",
        "- nltk.word_tokenize - \n",
        "- nltk.corpus.stopwords - lista de palavras consideradas \"stopwords\"\n",
        "- string - manipulação de strings\n",
        "- re - biblioteca python para operação de strings com codificação. No caso iremos trabalhar com a codificação dos emojis.\n",
        "- da biblioteca sklearn:\n",
        "    - MultinomialMB - algoritmo de Naive Beyes do tipo multinominal, o mais indicado para multiclassificação\n",
        "    - train_test_split - divide os dados em treino e teste\n",
        "    - accuracy_score - método utilizado para validar o modelo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pKwGD_QnHZPt"
      },
      "source": [
        "## funções utilizadas no notebook\n",
        "\n",
        "Para ajudar na leitura do notebook e minimizar as linhas de código durante a apresentação, serão feclaradas aqui no início as funções utilizadas na apresentação, inclusive a função `validate` pedida no desafio. O funcionamento dessas funções será explicado ao longo das apresentações."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qZ8FwmCqaqLI"
      },
      "source": [
        "def tratamento_reviews(df):\n",
        "    \n",
        "    # juntando o conteúdo das duas colunas de texto dos reviews\n",
        "    chars = [(df['review_headline'].iloc[i] + ' ' + df['review_body'].iloc[i])  \n",
        "             for i in df.index.to_list()]\n",
        "    df['review_total'] = chars\n",
        "\n",
        "    # preparando uma lista de emojis a serem excluídos \n",
        "    emoji_pattern = re.compile(\"[\"      \n",
        "        u\"\\U0001F300-\\U0001F5FF\"  # símbolos\n",
        "        u\"\\U0001F680-\\U0001F6FF\"  # transporte e símbolos de mapa\n",
        "        u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
        "        u\"\\U0000231A-\\U000023F3\"  # relógios e setas\n",
        "        u\"\\U000026A1-\\U000026BE\"  # relâmpago, cores e bolas de esportes\n",
        "        u\"\\U00002753-\\U00002757\"  # pontuação\n",
        "        u\"\\U00002B50\"             # estrela\n",
        "        u\"\\U0001F32D-\\U0001F37F\"  # comidas\n",
        "        u\"\\U0001F3A0-\\U0001F3D3\"  # esportes\n",
        "        u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
        "        u\"\\U0001F910-\\U0001F93E\"  # mais emoticons e emojis de esportes\n",
        "                           \"]+\", flags=re.UNICODE)\n",
        "    \n",
        "    # preparando para excluir os caracteres indesejados\n",
        "    col_corrigida = []      # lista para armazenar o conteúdo já tratado e a ser colocado na coluna review_total\n",
        "    char_excluir = string.punctuation + string.digits       # lista contendo caracteres a serem excluídos: caracteres escpeciais e dígitos\n",
        "\n",
        "    for row in df['review_total']:\n",
        "        temp = [char for char in row if char not in char_excluir]   # excluindo digitos e caracteres especiais\n",
        "        text = ''.join(temp).lower()\n",
        "        text = emoji_pattern.sub(r'', text)\n",
        "        for word in stopwords.words('english'):\n",
        "            text.replace(word, '')\n",
        "        col_corrigida.append(text)\n",
        "\n",
        "    df['review_total'] = col_corrigida\n",
        "\n",
        "    return df\n",
        "\n",
        "def tratamento_categorias(df):\n",
        "\n",
        "    df['num_category'] = df['product_category'].map({'Digital_Ebook_Purchase':0, \n",
        "       'Music':1, 'Video DVD':2, 'Mobile_Apps':3, 'Books':4, 'Electronics':5, \n",
        "       'Toys':6, 'Video Games':7, 'Digital_Video_Download':8, 'Digital_Music_Purchase':9, \n",
        "       'PC':10, 'Camera':11, 'Baby':12, 'Wireless':13, 'Home Entertainment':14, 'Sports':15,\n",
        "       'Musical Instruments':16, 'Lawn and Garden':17, 'Home Improvement':18, 'Home':19, \n",
        "       'Watches':20, 'Video':21, 'Shoes':22, 'Office Products':23, 'Automotive':24, \n",
        "       'Health & Personal Care':25, 'Personal_Care_Appliances':26, 'Software':27, \n",
        "       'Kitchen':28, 'Luggage':29, 'Pet Products':30, 'Beauty':31})\n",
        "    \n",
        "    return df\n",
        "\n",
        "def split_and_vect(df_ML, seed):\n",
        "    \n",
        "    x_train, x_test, y_train, y_test = train_test_split(df_ML['review_total'], df_ML['num_category'], random_state=seed)\n",
        "\n",
        "    vect = CountVectorizer(ngram_range=(2,2))\n",
        "    X_train = vect.fit_transform(x_train)\n",
        "    X_test = vect.transform(x_test)\n",
        "\n",
        "    return X_train, X_test, y_train, y_test, vect\n",
        "\n",
        "def validate(modelo, vect, df_teste):\n",
        "\n",
        "    df_tratado = tratamento_reviews(df_teste)       # tratando os textos de reviews\n",
        "\n",
        "    texto_vetorizado = vect.transform(df_tratado['review_total'])\n",
        "\n",
        "    df_tratado['product_category'] = modelo.predict(texto_vetorizado)  # realizando predição do modelo e atribuindo a uma nova coluna do df\n",
        "\n",
        "    # por fim, precisamos transformar de volta os tokers numéricos nas classes originais\n",
        "    df_tratado['product_category'] = df_tratado['product_category'].map({0:'Digital_Ebook_Purchase', \n",
        "       1:'Music', 2:'Video DVD', 3:'Mobile_Apps', 4:'Books', 5:'Electronics', \n",
        "       6:'Toys', 7:'Video Games', 8:'Digital_Video_Download', 9:'Digital_Music_Purchase', \n",
        "       10:'PC', 11:'Camera', 12:'Baby', 13:'Wireless', 14:'Home Entertainment', 15:'Sports',\n",
        "       16:'Musical Instruments', 17:'Lawn and Garden', 18:'Home Improvement', 19:'Home', \n",
        "       20:'Watches', 21:'Video', 22:'Shoes', 23:'Office Products', 24:'Automotive', \n",
        "       25:'Health & Personal Care', 26:'Personal_Care_Appliances', 27:'Software', \n",
        "       28:'Kitchen', 29:'Luggage', 30:'Pet Products', 31:'Beauty'})\n",
        "\n",
        "    return df_tratado.drop('review_total', axis=1)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "36kzk5Ol48OO"
      },
      "source": [
        "## obtenção dos dados e tratamento\n",
        "\n",
        "Os dados foram fornecidos pela empresa SOLVIMM, que propôs o desafio. Eles correspondem a uma base de dados de produtos cadastrados pela empresa \"Ponto Quente\"."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 442
        },
        "id": "RaJgpe5x5XdG",
        "outputId": "43465946-d493-4191-d1df-d60d5da34a8a"
      },
      "source": [
        "arq = 'https://github.com/matheus97eng/desafio_solvimm/blob/main/data/reviews.tsv?raw=true' # repositório do github\n",
        "df_original = pd.read_csv(arq, sep='\\t')\n",
        "print(df_original.shape)\n",
        "df_original.head()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(170583, 16)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>marketplace</th>\n",
              "      <th>customer_id</th>\n",
              "      <th>review_id</th>\n",
              "      <th>product_id</th>\n",
              "      <th>product_parent</th>\n",
              "      <th>product_title</th>\n",
              "      <th>star_rating</th>\n",
              "      <th>helpful_votes</th>\n",
              "      <th>total_votes</th>\n",
              "      <th>vine</th>\n",
              "      <th>verified_purchase</th>\n",
              "      <th>review_headline</th>\n",
              "      <th>review_body</th>\n",
              "      <th>review_date</th>\n",
              "      <th>product_category</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>762868</td>\n",
              "      <td>UK</td>\n",
              "      <td>29723892</td>\n",
              "      <td>R3VNENIATVV8QE</td>\n",
              "      <td>B00NOPQU2K</td>\n",
              "      <td>627793267</td>\n",
              "      <td>The Girl on the Train</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>N</td>\n",
              "      <td>N</td>\n",
              "      <td>Gripping you right where it matters</td>\n",
              "      <td>I know to say a story is &amp;#34;gripping&amp;#34; is...</td>\n",
              "      <td>2015-04-27</td>\n",
              "      <td>Digital_Ebook_Purchase</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1284183</td>\n",
              "      <td>UK</td>\n",
              "      <td>41072087</td>\n",
              "      <td>R2U3LV67N99770</td>\n",
              "      <td>B0013F2LSK</td>\n",
              "      <td>13214624</td>\n",
              "      <td>11</td>\n",
              "      <td>5</td>\n",
              "      <td>2</td>\n",
              "      <td>5</td>\n",
              "      <td>N</td>\n",
              "      <td>Y</td>\n",
              "      <td>The Best of Me</td>\n",
              "      <td>This album is totally fantastic, a great mix o...</td>\n",
              "      <td>2008-03-18</td>\n",
              "      <td>Music</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1599315</td>\n",
              "      <td>UK</td>\n",
              "      <td>49938094</td>\n",
              "      <td>R3RO94POCHNI9V</td>\n",
              "      <td>B005CVWWJY</td>\n",
              "      <td>769273676</td>\n",
              "      <td>Ready Player One</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>N</td>\n",
              "      <td>Y</td>\n",
              "      <td>superb</td>\n",
              "      <td>Enjoyed every second of this book.  It took me...</td>\n",
              "      <td>2014-08-28</td>\n",
              "      <td>Digital_Ebook_Purchase</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>204782</td>\n",
              "      <td>UK</td>\n",
              "      <td>14398213</td>\n",
              "      <td>R3S2BB5SBWBC1</td>\n",
              "      <td>B00008AWV3</td>\n",
              "      <td>841759677</td>\n",
              "      <td>The Four Feathers [DVD] [1939]</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>N</td>\n",
              "      <td>Y</td>\n",
              "      <td>Sweeping, authentic historic drama</td>\n",
              "      <td>I loved the historic scenes---the English coun...</td>\n",
              "      <td>2013-12-27</td>\n",
              "      <td>Video DVD</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>352938</td>\n",
              "      <td>UK</td>\n",
              "      <td>20140500</td>\n",
              "      <td>R27E2PNXJSWJIN</td>\n",
              "      <td>B00FAXJHCY</td>\n",
              "      <td>803172158</td>\n",
              "      <td>The Martian</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>N</td>\n",
              "      <td>Y</td>\n",
              "      <td>... a few pages to get through it but a good b...</td>\n",
              "      <td>May have skipped a few pages to get through it...</td>\n",
              "      <td>2015-06-06</td>\n",
              "      <td>Digital_Ebook_Purchase</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Unnamed: 0 marketplace  ...  review_date        product_category\n",
              "0      762868          UK  ...   2015-04-27  Digital_Ebook_Purchase\n",
              "1     1284183          UK  ...   2008-03-18                   Music\n",
              "2     1599315          UK  ...   2014-08-28  Digital_Ebook_Purchase\n",
              "3      204782          UK  ...   2013-12-27               Video DVD\n",
              "4      352938          UK  ...   2015-06-06  Digital_Ebook_Purchase\n",
              "\n",
              "[5 rows x 16 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c6d4bKjBqB6p"
      },
      "source": [
        "### Informações das features, exclusão de dados nulos e explicação do modelo:\n",
        "\n",
        "Vamos obter uma visão geral das features em questão."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 420
        },
        "id": "KI6zuFATqBUZ",
        "outputId": "4e699969-179f-4209-a0c2-a1db4b0532ed"
      },
      "source": [
        "display(df_original.info())"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 170583 entries, 0 to 170582\n",
            "Data columns (total 16 columns):\n",
            " #   Column             Non-Null Count   Dtype \n",
            "---  ------             --------------   ----- \n",
            " 0   Unnamed: 0         170583 non-null  int64 \n",
            " 1   marketplace        170583 non-null  object\n",
            " 2   customer_id        170583 non-null  int64 \n",
            " 3   review_id          170583 non-null  object\n",
            " 4   product_id         170583 non-null  object\n",
            " 5   product_parent     170583 non-null  int64 \n",
            " 6   product_title      170583 non-null  object\n",
            " 7   star_rating        170583 non-null  int64 \n",
            " 8   helpful_votes      170583 non-null  int64 \n",
            " 9   total_votes        170583 non-null  int64 \n",
            " 10  vine               170583 non-null  object\n",
            " 11  verified_purchase  170583 non-null  object\n",
            " 12  review_headline    170583 non-null  object\n",
            " 13  review_body        170582 non-null  object\n",
            " 14  review_date        170578 non-null  object\n",
            " 15  product_category   170583 non-null  object\n",
            "dtypes: int64(6), object(10)\n",
            "memory usage: 20.8+ MB\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "None"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AAxkps_W2GIo"
      },
      "source": [
        "O desafio pede para classificar os produtos somente de acordo com os reviews feitos pelos clientes. Esclarecido isso, não precisamos nos preocupar com outras features, a não ser: `review_headline`, que é o título da avaliação, `review_body`, que é a avaliação em si e por fim, `product_category`, que é a categorização corrigida do produto. Aqui não consideraremos relevante a data de postagem do review, nem o ID do review.\n",
        "\n",
        "Dado que as features `review_headline` e `product_category` são todas texto (do tipo caracter), e por se tratar de um problema de classificação (identificar qual a classe que o produto pertence), precisamos de um modelo que utilize NPL (Natural Language Processing). Será escolhido o algoritmo de [Naive Beyes](https://www.analyticsvidhya.com/blog/2017/09/naive-bayes-explained/), pois é um algoritmo de fácil aplicação com python e sklearn, tem uma boa resposta dado uma quantidade pequena de dados e não é um algoritmo pesado. \n",
        "\n",
        "Explicando de uma forma não formal, o algoritmo de Nave Beyes trabalha calculando qual é a probabilidade de um produto ser da classe \"X\" sendo que no review desse produto encontramos certas \"palavras-chave\". Treinando o modelo, ele consegue identificar, por exemplo que, se no review aparecer a palavra \"bola\", é mais provável que o produto seja da categoria \"esportes\". Com as informações da base de dados, o algoritmo estará treinado e validado para classificar outros produtos, fora da base de dados preparada pelo time de dados da \"Ponto Quente\". \n",
        "\n",
        "Uma desvantagem desse modelo é que ele não considera a semântica do texto. Por exemplo, ao olhar para a frase \"meus dedos ficaram muito apertados quando eu testei na corrida\". Analisando o contexto, poderíamos identificar que o produto se trata provavelmente de um tênis. Mas o Nave Beyes analisa palavra por palavra, separadamente, o que tornaria mais difícil a identificação, nesse exemplo dado.\n",
        "\n",
        "No entanto, antes de modelar nosso problema, precisamos tratar os nossos dados.\n",
        "Executando `df_original.info()` já vemos que a feature `review_body` possui uma linha com dado nulo. Isso porque vemos 170582 dados não nulos nessa coluna, enquanto que a nossa base de dados possui 170583 linhas. Vamos optar por excluir toda a linha que contém esse dado nulo, já que atrapalhará no desenvolvimento do modelo e se trata apenas de um produto."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "68Co4Ztj2Frg",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 425
        },
        "outputId": "0bc8f058-d177-4c34-a344-1c7c21541bcc"
      },
      "source": [
        "excluir = df_original[df_original['review_body'].isnull()].index\n",
        "df_tratado = df_original.drop(excluir).reset_index(drop=True)\n",
        "df_tratado.head()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>marketplace</th>\n",
              "      <th>customer_id</th>\n",
              "      <th>review_id</th>\n",
              "      <th>product_id</th>\n",
              "      <th>product_parent</th>\n",
              "      <th>product_title</th>\n",
              "      <th>star_rating</th>\n",
              "      <th>helpful_votes</th>\n",
              "      <th>total_votes</th>\n",
              "      <th>vine</th>\n",
              "      <th>verified_purchase</th>\n",
              "      <th>review_headline</th>\n",
              "      <th>review_body</th>\n",
              "      <th>review_date</th>\n",
              "      <th>product_category</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>762868</td>\n",
              "      <td>UK</td>\n",
              "      <td>29723892</td>\n",
              "      <td>R3VNENIATVV8QE</td>\n",
              "      <td>B00NOPQU2K</td>\n",
              "      <td>627793267</td>\n",
              "      <td>The Girl on the Train</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>N</td>\n",
              "      <td>N</td>\n",
              "      <td>Gripping you right where it matters</td>\n",
              "      <td>I know to say a story is &amp;#34;gripping&amp;#34; is...</td>\n",
              "      <td>2015-04-27</td>\n",
              "      <td>Digital_Ebook_Purchase</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1284183</td>\n",
              "      <td>UK</td>\n",
              "      <td>41072087</td>\n",
              "      <td>R2U3LV67N99770</td>\n",
              "      <td>B0013F2LSK</td>\n",
              "      <td>13214624</td>\n",
              "      <td>11</td>\n",
              "      <td>5</td>\n",
              "      <td>2</td>\n",
              "      <td>5</td>\n",
              "      <td>N</td>\n",
              "      <td>Y</td>\n",
              "      <td>The Best of Me</td>\n",
              "      <td>This album is totally fantastic, a great mix o...</td>\n",
              "      <td>2008-03-18</td>\n",
              "      <td>Music</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1599315</td>\n",
              "      <td>UK</td>\n",
              "      <td>49938094</td>\n",
              "      <td>R3RO94POCHNI9V</td>\n",
              "      <td>B005CVWWJY</td>\n",
              "      <td>769273676</td>\n",
              "      <td>Ready Player One</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>N</td>\n",
              "      <td>Y</td>\n",
              "      <td>superb</td>\n",
              "      <td>Enjoyed every second of this book.  It took me...</td>\n",
              "      <td>2014-08-28</td>\n",
              "      <td>Digital_Ebook_Purchase</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>204782</td>\n",
              "      <td>UK</td>\n",
              "      <td>14398213</td>\n",
              "      <td>R3S2BB5SBWBC1</td>\n",
              "      <td>B00008AWV3</td>\n",
              "      <td>841759677</td>\n",
              "      <td>The Four Feathers [DVD] [1939]</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>N</td>\n",
              "      <td>Y</td>\n",
              "      <td>Sweeping, authentic historic drama</td>\n",
              "      <td>I loved the historic scenes---the English coun...</td>\n",
              "      <td>2013-12-27</td>\n",
              "      <td>Video DVD</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>352938</td>\n",
              "      <td>UK</td>\n",
              "      <td>20140500</td>\n",
              "      <td>R27E2PNXJSWJIN</td>\n",
              "      <td>B00FAXJHCY</td>\n",
              "      <td>803172158</td>\n",
              "      <td>The Martian</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>N</td>\n",
              "      <td>Y</td>\n",
              "      <td>... a few pages to get through it but a good b...</td>\n",
              "      <td>May have skipped a few pages to get through it...</td>\n",
              "      <td>2015-06-06</td>\n",
              "      <td>Digital_Ebook_Purchase</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Unnamed: 0 marketplace  ...  review_date        product_category\n",
              "0      762868          UK  ...   2015-04-27  Digital_Ebook_Purchase\n",
              "1     1284183          UK  ...   2008-03-18                   Music\n",
              "2     1599315          UK  ...   2014-08-28  Digital_Ebook_Purchase\n",
              "3      204782          UK  ...   2013-12-27               Video DVD\n",
              "4      352938          UK  ...   2015-06-06  Digital_Ebook_Purchase\n",
              "\n",
              "[5 rows x 16 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IzJxBq6Uv3Uy"
      },
      "source": [
        "### Features de review dos clientes\n",
        "\n",
        "Há duas colunas no dataframe com o conteúdo de avaliações dos clientes: `review_headline`, que contém o título da avaliação, e `review_body`, que contém o corpo do review. O que será feito nesse desafio será juntar todas as palavras dessas duas features em uma coluna apenas, já que o contexto do texto não importa no modelo de Naive Beyes. O nome da coluna contendo o texto compactado será `review_total`.\n",
        "\n",
        "Além disso, precisamos fazer a limpeza desse texto. Será tirado todos os caracteres especiais, dígitos e uma lista de emojis. Além disso, serão removidas as chamadas **\"stop-words\"**, que são basicamente palavras que não nos fornecem muita informação quando analisadas separadamente. São palavras como \"I, yourself, the...\". A biblioteca `ntlk` possui uma lista dessas palavras. Será usado essa lista como base. Feito a limpeza, garantimos o melhor funcionamento do modelo, que analisará apenas palavras-chave dos dados.\n",
        "\n",
        "**obs.:** não serão excluídos todos os emojis possíveis. A lista de todos os emojis codificados é muito grande e poderia fazer o programa demorar muito para ser executado. Foram escolhidos emojis que são mais prováveis de aparecer em produtos. A lista de emojis a serem excluídos pode ser editada na própria função `tratamento_review`, que faz a limpeza dos textos dos reviews."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oq_qJkCiv54f"
      },
      "source": [
        "### Tipos de classificação\n",
        "\n",
        "É importante também olharmos para os tipos de classificação de produtos que a empresa tem. Na base fornecida, foram identificados 32 classes. É essencial entender que o modelo a ser treinado **não identificará classes de produtos que não estão na base de dados**. Desse modo, se a empresa quisesse identificar um produto como classe \"carro\" ou não, teria que acrescentar à base de dados vários produtos da categoria \"carro\".\n",
        "\n",
        "O modelo de machine learning não consegue interpretar dados do tipo string. Portanto, precisamos alterar os dados da coluna alvo `product_category`, fazendo uma tokerização simples, em outras palavras, substituindo as palavras por números. Os valores substituídos serão armazenados em uma coluna chamada `num_category`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iXiO-sYLaI2o"
      },
      "source": [
        "### execução das funções de tratamento do dataframe\n",
        "\n",
        "Todo esse tratamento descrito acima será feito por duas funções: `tratamento_reviews`, que tratará todo o conteúdo dos reviews dos clientes e `tratamento_categorias`, que tratará o conteúdo da coluna `product_category`. Enquanto que a primeira função retorna o dataframe acrescentado da coluna `review_total` (coluna esta que é criada pela próppria função), a segunda função reotornará o dataframe com os dados preparados para ser desenvolvido o modelo. Esse dataframe será chamado `df_ML` e conterá a coluna `review_total`, que será a variável x do modelo, e a coluna `num_category`, que será a variável y."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kTVAk4IABWjm"
      },
      "source": [
        "df_tratado = tratamento_reviews(df_tratado)\n",
        "df_ML = tratamento_categorias(df_tratado)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gMeQQhJstcf3"
      },
      "source": [
        "## Aplicação do machine learning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OrZ7Rhq4xyCg"
      },
      "source": [
        "### divisão dos dados em treino e teste / treinamento do modelo\n",
        "\n",
        "Após os tratamentos feitos, vamos separar os dados em treino e teste para o modelo. No entanto, mais uma transformação deverá ser feita na coluna `review_total`. Precisamos fazer a tokerização (ou vetorização) das palavras, além de transformar a coluna em uma matriz esparça, que é a entrada que o método `fit` do modelo `MultinomialNB` aceita. Para isso utilizaremos a classe `CountVectorizer` da biblioteca `sklearn`. Aqui, os dados da vetorização e da transformação em matriz esparça serão armazenados nas variáveis `X_train` e `X_test` (com X maiúsculo). A transformação será feita em cima de `x_train` e `x_test` (com x minúsculo), variáveis que serão preparadas através do método `train_test_split`, também da biblioteca `sklearn`. Estas variáveis são apenas uma separação dos dados de `df_ML`.\n",
        "\n",
        "Todo esse processo, bem como o treinamento do modelo, serão realizados pela função `split_and_vect`, que retornará as matrizes esparças `X_train` e `X_test` e os arrays `y_train` e `y_test`. Além dessas variáveis, a função retornará também a instância `vect`, que será utilizada na função `validate` para tokerizar as palavras dos textos. Os parâmetros que esta função recebe são o dataframe (que deve ser tratado pelas duas funções de tratamento) e o número `seed`, que garante a reprodutibilidade do modelo. Aqui executaremos a função com seed = 50."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SLMjDh0B4Dz-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "84dabfe6-c20d-4530-8db6-605b9692f145"
      },
      "source": [
        "X_train, X_test, y_train, y_test, vect = split_and_vect(df_ML, 50)\n",
        "\n",
        "modelo = MultinomialNB(alpha=0.2)\n",
        "modelo.fit(X_train,y_train)\n",
        "\n",
        "result = modelo.predict(X_test)\n",
        "print(result)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2 2 3 ... 2 4 1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qjvCfq0itQ5Z"
      },
      "source": [
        "### validação do modelo\n",
        "\n",
        "Para validar o modelo, utilizaremos o proposto pelo desafio da Solvimm, que é calcular a acurácia. Isso será calculado através da biblioteca `sklearn`.\n",
        "\n",
        "O modelo desenvolvido aqui apresenta uma acurácia de aproximadamente 73,24%. Em outras palavras, com a divisão dos dados feitas aqui e com esse modelo treinado, estamos acertando praticamente a classificação de 3 a cada 4 produtos. Essa é uma acurácia maior do que o mínimo esperado no desafio."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dXHyItV15ju1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5e8fd53a-99d3-4eae-e651-6af1fa9da67c"
      },
      "source": [
        "accuracy_score(result,y_test)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7324250808985603"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yvi8pJKJu6U2"
      },
      "source": [
        "## Aplicando o modelo: função validate\n",
        "\n",
        "Por fim, após o tratamento, treinamento e validação do modelo, resta desenvolver uma função que aplique nosso modelo a um dataframe, afim de classificar os produtos nele contidos. Para isso, utilizaremos a função `validate`, que recebe o modelo treinado, a função vect e um dataframe como o fornecido pela equipe da \"Ponto Quente\", mas sem a coluna `product_category`. A função deve retornar o mesmo dataframe de entrada, porém com a coluna `product_category` que terá as categorias previstas para cada produto.\n",
        "\n",
        "Não faz sentido nenhum executar esta função sobre a base de dados fornecida pela \"Ponto Quente\" para preparar o modelo, já que as classificações dos produtos já foram corrigidas pelo time da empresa. No entanto, utilizaremos a mesma base de dados apenas para verificar o funcionamento da função, uma vez que o modelo já está validado.\n",
        "\n",
        "É importante dizer que, antes de fazer de fato a predição do modelo, o dataframe que a função `validate` recebe precisa ser tratado, assim como fizemos o tratamento dos textos dos reviews antes de treinar o modelo. Mais especificamente, o dataframe precisa passar antes pela função `tratamento_reviews`, o que leva boa parte do tempo de execução de `validate`. Além disso, dentro da função precisa ser feita a tokerização das palavras, por isso o parâmetro `vect` deve ser fornecido. Sem esse parâmetro, não teria como a empresa \"Ponto Quente\" usar a função `validate` sem executar antes \n",
        "\n",
        "O dataframe que será utilizado como parâmetro de execução da função será `df_tratado`, e não `df_original`, aquele retirado diretamente da base fornecida pelo time de dados. Isso porque **o dataframe que `validate` recebe não pode conter dados nulos nos reviews**. Não será implementado nenhuma linha de código para tratar dados nulos, porque isso seria melhor feito sendo conversado com a empresa. É fácil entender o porque: digamos que a empresa aplique o algoritmo numa dataframe com vários dados nulos. Ela gostaria que simplesmente ignorássemos os produtos que não tiveram reviews ou desejaria que fosse feito um outro tipo de tratamento no algoritmo? Cabe a empresa decidir."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-S_R6bin-C90"
      },
      "source": [
        "df_sem_categoria = df_tratado.drop(['product_category', 'review_total'], axis=1).sample(100).reset_index(drop=True)\n",
        "\n",
        "df_categorizado = validate(modelo, vect, df_sem_categoria)\n",
        "\n",
        "df_categorizado.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w-r1bipgN-0_"
      },
      "source": [
        "## Conclusões e possíveis ponto de melhoria\n",
        "\n",
        "Por fim, considera-se como satisfatório o modelo desenvolvido para este desafio, que passou no critério de pontuação da acurácia do processo seletivo. Ele possui um tempo de execução bem aceitável, ainda mais dado o tamanho do dataset fornecido para treino e teste, que supera as 170 mil linhas. Isso não impede de serem estudadas algumas melhorias nas implementações e estruturação das funções.\n",
        "\n",
        "Ainda poderia ser explorado os parâmetros do algoritmo `MultinomialNB`, para verificar as implicações e possíveis melhorias na acurácia do modelo.\n",
        "\n",
        "No entanto, como dito, o algoritmo de Naive Beyes não considera contextualização de textos. Por isso, outros algoritmos como o BERT, que consideram interpretação de texto, possam apresentar uma pontuação de acurácia melhor. \n",
        "\n",
        "Como foi dito, foi também desconsiderado os emojis. Pode ser que usar os emojis como dados para o treinamento do modelo funcione melhor do que simplesmente ignorá-los. Por exemplo, um emoji de câmera pode dizer que, de fato, o produto que recebeu o review é uma câmera. Isso no entanto é algo que precisa de uma extensa base de dados contendo emojis, pois as pessoas os utilizam de maneiras diferentes com propósitos diferentes. "
      ]
    }
  ]
}