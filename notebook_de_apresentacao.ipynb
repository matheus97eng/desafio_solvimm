{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "notebook_de_apresentacao.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/matheus97eng/desafio_solvimm/blob/main/notebook_de_apresentacao.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3rxknMGz5h9B"
      },
      "source": [
        "importando bibliotecas"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "--p0-yqB5hgH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6a0ce0da-0ca1-497a-e65a-26f672c9cf13"
      },
      "source": [
        "import pandas as pd\n",
        "import string, re, nltk\n",
        "#from nltk import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "nltk.download('stopwords')      # obtem as stopwords"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2YMITy_gz2ug"
      },
      "source": [
        "- pandas - manipulação de dataframes\n",
        "- nltk.word_tokenize - \n",
        "- nltk.corpus.stopwords - lista de palavras consideradas \"stopwords\"\n",
        "- string - manipulação de strings\n",
        "- re - biblioteca python para operação de strings com codificação. No caso iremos trabalhar com a codificação dos emojis.\n",
        "- da biblioteca sklearn:\n",
        "    - MultinomialMB - algoritmo de Naive Beyes do tipo multinominal, o mais indicado para multiclassificação\n",
        "    - train_test_split - divide os dados em treino e teste\n",
        "    - accuracy_score - método utilizado para validar o modelo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pKwGD_QnHZPt"
      },
      "source": [
        "## funções utilizadas no notebook"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qZ8FwmCqaqLI"
      },
      "source": [
        "def tratamento_reviews(df):\n",
        "    \n",
        "    # juntando o conteúdo das duas colunas de texto dos reviews\n",
        "    chars = [(df['review_headline'].iloc[i] + ' ' + df['review_body'].iloc[i])  \n",
        "             for i in df.index.to_list()]\n",
        "    df['review_total'] = chars\n",
        "\n",
        "    # preparando uma lista de emojis a serem excluídos \n",
        "    emoji_pattern = re.compile(\"[\"      \n",
        "        u\"\\U0001F300-\\U0001F5FF\"  # símbolos\n",
        "        u\"\\U0001F680-\\U0001F6FF\"  # transporte e símbolos de mapa\n",
        "        u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
        "        u\"\\U0000231A-\\U000023F3\"  # relógios e setas\n",
        "        u\"\\U000026A1-\\U000026BE\"  # relâmpago, cores e bolas de esportes\n",
        "        u\"\\U00002753-\\U00002757\"  # pontuação\n",
        "        u\"\\U00002B50\"             # estrela\n",
        "        u\"\\U0001F32D-\\U0001F37F\"  # comidas\n",
        "        u\"\\U0001F3A0-\\U0001F3D3\"  # esportes\n",
        "        u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
        "        u\"\\U0001F910-\\U0001F93E\"  # mais emoticons e emojis de esportes\n",
        "                           \"]+\", flags=re.UNICODE)\n",
        "    \n",
        "    # preparando para excluir os caracteres indesejados\n",
        "    col_corrigida = []      # lista para armazenar o conteúdo já tratado e a ser colocado na coluna review_total\n",
        "    char_excluir = string.punctuation + string.digits       # lista contendo caracteres a serem excluídos: caracteres escpeciais e dígitos\n",
        "\n",
        "    for row in df_tratado['review_total']:\n",
        "        temp = [char for char in row if char not in char_excluir]   # excluindo digitos e caracteres especiais\n",
        "        text = ''.join(temp).lower()\n",
        "        text = emoji_pattern.sub(r'', text)\n",
        "        for word in stopwords.words('english'):\n",
        "            text.replace(word, '')\n",
        "        col_corrigida.append(text)\n",
        "\n",
        "    df['review_total'] = col_corrigida\n",
        "\n",
        "    return df\n",
        "\n",
        "def tratamento_categorias(df):\n",
        "\n",
        "    df['num_category'] = df['product_category'].map({'Digital_Ebook_Purchase':0, \n",
        "       'Music':1, 'Video DVD':2, 'Mobile_Apps':3, 'Books':4, 'Electronics':5, \n",
        "       'Toys':6, 'Video Games':7, 'Digital_Video_Download':8, 'Digital_Music_Purchase':9, \n",
        "       'PC':10, 'Camera':11, 'Baby':12, 'Wireless':13, 'Home Entertainment':14, 'Sports':15,\n",
        "       'Musical Instruments':16, 'Lawn and Garden':17, 'Home Improvement':18, 'Home':19, \n",
        "       'Watches':20, 'Video':21, 'Shoes':22, 'Office Products':23, 'Automotive':24, \n",
        "       'Health & Personal Care':25, 'Personal_Care_Appliances':26, 'Software':27, \n",
        "       'Kitchen':28, 'Luggage':29, 'Pet Products':30, 'Beauty':31})\n",
        "    \n",
        "    return df\n",
        "\n",
        "def treina_modelo(df_ML, seed):\n",
        "    \n",
        "    x_train, x_test, y_train, y_test = train_test_split(df_ML['review_total'], df_ML['num_category'], random_state=seed)\n",
        "\n",
        "    vect = CountVectorizer(ngram_range=(2,2))\n",
        "    X_train = vect.fit_transform(x_train)\n",
        "    X_test = vect.transform(x_test)\n",
        "\n",
        "    modelo = MultinomialNB(alpha=0.2)\n",
        "\n",
        "    modelo.fit(X_train,y_train)\n",
        "\n",
        "    return X_train, X_test, y_train, y_test, modelo, vect\n",
        "\n",
        "def validate(modelo, vect, df_teste):\n",
        "\n",
        "    df_tratado = tratamento_reviews(df_teste)       # tratando os textos de reviews\n",
        "\n",
        "    texto_vetorizado = vect.transform(df_teste_tratado['review_total'])\n",
        "\n",
        "    df_tratado['product_category'] = mnb.predict(texto_vetorizado)  # realizando predição do modelo e atribuindo a uma nova coluna do df\n",
        "\n",
        "    # por fim, precisamos transformar de volta os tokers numéricos nas classes originais\n",
        "    df_tratado['product_category'] = df_tratado['product_category'].map({0:'Digital_Ebook_Purchase', \n",
        "       1:'Music', 2:'Video DVD', 3:'Mobile_Apps', 4:'Books', 5:'Electronics', \n",
        "       6:'Toys', 7:'Video Games', 8:'Digital_Video_Download', 9:'Digital_Music_Purchase', \n",
        "       10:'PC', 11:'Camera', 12:'Baby', 13:'Wireless', 14:'Home Entertainment', 15:'Sports',\n",
        "       16:'Musical Instruments', 17:'Lawn and Garden', 18:'Home Improvement', 19:'Home', \n",
        "       20:'Watches', 21:'Video', 22:'Shoes', 23:'Office Products', 24:'Automotive', \n",
        "       25:'Health & Personal Care', 26:'Personal_Care_Appliances', 27:'Software', \n",
        "       28:'Kitchen', 29:'Luggage', 30:'Pet Products', 31:'Beauty'})\n",
        "\n",
        "    return df_tratado.drop('review_total', axis=1)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "36kzk5Ol48OO"
      },
      "source": [
        "## obtenção dos dados e tratamento\n",
        "\n",
        "Os dados foram fornecidos pela empresa SOLVIMM, que propôs o desafio. Eles correspondem a uma base de dados de produtos cadastrados pela empresa \"Ponto Quente\"."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 442
        },
        "id": "RaJgpe5x5XdG",
        "outputId": "bc3d9d44-86bd-4dd3-d003-535d3b560896"
      },
      "source": [
        "arq = 'https://github.com/matheus97eng/desafio_solvimm/blob/main/data/reviews.tsv?raw=true' # repositório do github\n",
        "df_original = pd.read_csv(arq, sep='\\t')\n",
        "print(df_original.shape)\n",
        "df_original.head()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(170583, 16)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>marketplace</th>\n",
              "      <th>customer_id</th>\n",
              "      <th>review_id</th>\n",
              "      <th>product_id</th>\n",
              "      <th>product_parent</th>\n",
              "      <th>product_title</th>\n",
              "      <th>star_rating</th>\n",
              "      <th>helpful_votes</th>\n",
              "      <th>total_votes</th>\n",
              "      <th>vine</th>\n",
              "      <th>verified_purchase</th>\n",
              "      <th>review_headline</th>\n",
              "      <th>review_body</th>\n",
              "      <th>review_date</th>\n",
              "      <th>product_category</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>762868</td>\n",
              "      <td>UK</td>\n",
              "      <td>29723892</td>\n",
              "      <td>R3VNENIATVV8QE</td>\n",
              "      <td>B00NOPQU2K</td>\n",
              "      <td>627793267</td>\n",
              "      <td>The Girl on the Train</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>N</td>\n",
              "      <td>N</td>\n",
              "      <td>Gripping you right where it matters</td>\n",
              "      <td>I know to say a story is &amp;#34;gripping&amp;#34; is...</td>\n",
              "      <td>2015-04-27</td>\n",
              "      <td>Digital_Ebook_Purchase</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1284183</td>\n",
              "      <td>UK</td>\n",
              "      <td>41072087</td>\n",
              "      <td>R2U3LV67N99770</td>\n",
              "      <td>B0013F2LSK</td>\n",
              "      <td>13214624</td>\n",
              "      <td>11</td>\n",
              "      <td>5</td>\n",
              "      <td>2</td>\n",
              "      <td>5</td>\n",
              "      <td>N</td>\n",
              "      <td>Y</td>\n",
              "      <td>The Best of Me</td>\n",
              "      <td>This album is totally fantastic, a great mix o...</td>\n",
              "      <td>2008-03-18</td>\n",
              "      <td>Music</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1599315</td>\n",
              "      <td>UK</td>\n",
              "      <td>49938094</td>\n",
              "      <td>R3RO94POCHNI9V</td>\n",
              "      <td>B005CVWWJY</td>\n",
              "      <td>769273676</td>\n",
              "      <td>Ready Player One</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>N</td>\n",
              "      <td>Y</td>\n",
              "      <td>superb</td>\n",
              "      <td>Enjoyed every second of this book.  It took me...</td>\n",
              "      <td>2014-08-28</td>\n",
              "      <td>Digital_Ebook_Purchase</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>204782</td>\n",
              "      <td>UK</td>\n",
              "      <td>14398213</td>\n",
              "      <td>R3S2BB5SBWBC1</td>\n",
              "      <td>B00008AWV3</td>\n",
              "      <td>841759677</td>\n",
              "      <td>The Four Feathers [DVD] [1939]</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>N</td>\n",
              "      <td>Y</td>\n",
              "      <td>Sweeping, authentic historic drama</td>\n",
              "      <td>I loved the historic scenes---the English coun...</td>\n",
              "      <td>2013-12-27</td>\n",
              "      <td>Video DVD</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>352938</td>\n",
              "      <td>UK</td>\n",
              "      <td>20140500</td>\n",
              "      <td>R27E2PNXJSWJIN</td>\n",
              "      <td>B00FAXJHCY</td>\n",
              "      <td>803172158</td>\n",
              "      <td>The Martian</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>N</td>\n",
              "      <td>Y</td>\n",
              "      <td>... a few pages to get through it but a good b...</td>\n",
              "      <td>May have skipped a few pages to get through it...</td>\n",
              "      <td>2015-06-06</td>\n",
              "      <td>Digital_Ebook_Purchase</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Unnamed: 0 marketplace  ...  review_date        product_category\n",
              "0      762868          UK  ...   2015-04-27  Digital_Ebook_Purchase\n",
              "1     1284183          UK  ...   2008-03-18                   Music\n",
              "2     1599315          UK  ...   2014-08-28  Digital_Ebook_Purchase\n",
              "3      204782          UK  ...   2013-12-27               Video DVD\n",
              "4      352938          UK  ...   2015-06-06  Digital_Ebook_Purchase\n",
              "\n",
              "[5 rows x 16 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c6d4bKjBqB6p"
      },
      "source": [
        "### Informações das features, exclusão de dados nulos e explicação do modelo:\n",
        "\n",
        "Vamos obter uma visão geral das features em questão."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 420
        },
        "id": "KI6zuFATqBUZ",
        "outputId": "e9d8a681-76c2-4e7c-dba4-8936f76eef2f"
      },
      "source": [
        "display(df_original.info())"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 170583 entries, 0 to 170582\n",
            "Data columns (total 16 columns):\n",
            " #   Column             Non-Null Count   Dtype \n",
            "---  ------             --------------   ----- \n",
            " 0   Unnamed: 0         170583 non-null  int64 \n",
            " 1   marketplace        170583 non-null  object\n",
            " 2   customer_id        170583 non-null  int64 \n",
            " 3   review_id          170583 non-null  object\n",
            " 4   product_id         170583 non-null  object\n",
            " 5   product_parent     170583 non-null  int64 \n",
            " 6   product_title      170583 non-null  object\n",
            " 7   star_rating        170583 non-null  int64 \n",
            " 8   helpful_votes      170583 non-null  int64 \n",
            " 9   total_votes        170583 non-null  int64 \n",
            " 10  vine               170583 non-null  object\n",
            " 11  verified_purchase  170583 non-null  object\n",
            " 12  review_headline    170583 non-null  object\n",
            " 13  review_body        170582 non-null  object\n",
            " 14  review_date        170578 non-null  object\n",
            " 15  product_category   170583 non-null  object\n",
            "dtypes: int64(6), object(10)\n",
            "memory usage: 20.8+ MB\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "None"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AAxkps_W2GIo"
      },
      "source": [
        "O desafio nos pede para classificar os produtos somente de acordo com os reviews feitos pelos clientes. Esclarecido isso, não precisamos nos preocupar com outras features, a não ser: `review_headline`, que é o título da avaliação, `review_body`, que é a avaliação em si e por fim, `product_category`, que é a categorização corrigida do produto. Aqui não consideraremos relevante a data de postagem do review, nem o ID do review.\n",
        "\n",
        "Dado que as features `review_headline` e `product_category` são todas texto (do tipo caracter), e por se tratar de um problema de classificação (identificar qual a classe que o produto pertence), precisamos de um modelo que utilize NPL (Natural Language Processing). Será escolhido o algoritmo de [Nave Beyes](https://www.analyticsvidhya.com/blog/2017/09/naive-bayes-explained/), pois é um algoritmo de fácil aplicação com python e sklearn, tem uma boa resposta dado uma quantidade pequena de dados e não é um algoritmo pesado. \n",
        "\n",
        "Explicando de uma forma não formal, o algoritmo de Nave Beyes trabalha calculando qual é a probabilidade de um produto ser da classe \"X\" sendo que no review desse produto encontramos certas \"palavras-chave\". Treinando o modelo, ele consegue identificar, por exemplo que, se no review aparecer a palavra \"bola\", é mais provável que o produto seja da categoria \"esportes\". Com as informações da base de dados, o algoritmo estará treinado e validado para classificar outros produtos, fora da base de dados preparada pelo time de dados da \"Ponto Quente\". \n",
        "\n",
        "Uma desvantagem desse modelo é que ele não considera a semântica do texto. Por exemplo, ao olhar para a frase \"meus dedos ficaram muito apertados quando eu testei na corrida\". Analisando o contexto, poderíamos identificar que o produto se trata provavelmente de um tênis. Mas o Nave Beyes analisa palavra por palavra, separadamente, o que tornaria mais difícil a identificação, nesse exemplo dado.\n",
        "\n",
        "No entanto, antes de modelar nosso problema, precisamos tratar os nossos dados.\n",
        "Executando `df_original.info()` já vemos que a feature `review_body` possui uma linha com dado nulo. Isso porque vemos 170582 dados não nulos nessa coluna, enquanto que a nossa base de dados possui 170583 linhas. Vamos optar por excluir toda a linha que contém esse dado nulo, já que atrapalhará no desenvolvimento do modelo e se trata apenas de um produto."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "68Co4Ztj2Frg"
      },
      "source": [
        "excluir = df_original[df_original['review_body'].isnull()].index\n",
        "df_tratado = df_original.drop(excluir).reset_index()"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IzJxBq6Uv3Uy"
      },
      "source": [
        "### Features de review dos clientes\n",
        "\n",
        "Há duas colunas no dataframe com o conteúdo de avaliações dos clientes: `review_headline`, que contém o título da avaliação, e `review_body`, que contém o corpo do review. O que será feito nesse desafio será juntar todas as palavras dessas duas features em uma coluna apenas, já que o contexto do texto não importa no modelo de Naive Beyes. O nome da coluna contendo o texto compactado será `review_total`.\n",
        "\n",
        "Além disso, precisamos fazer a limpeza desse texto. Será tirado todos os caracteres especiais, dígitos e uma lista de emojis. Além disso, serão removidas as chamadas **\"stop-words\"**, que são basicamente palavras que não nos fornecem muita informação quando analisadas separadamente. São palavras como \"I, yourself, the...\". A biblioteca `ntlk` possui uma lista dessas palavras. Será usado essa lista como base. Feito a limpeza, garantimos o melhor funcionamento do modelo, que analisará apenas palavras-chave dos dados.\n",
        "\n",
        "**obs.:** não serão excluídos todos os emojis possíveis. A lista de todos os emojis codificados é muito grande e poderia fazer o programa demorar muito para ser executado. Foram escolhidos emojis que são mais prováveis de aparecer em produtos. A lista de emojis a serem excluídos pode ser editada na própria função `tratamento_review`, que faz a limpeza dos textos dos reviews."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oq_qJkCiv54f"
      },
      "source": [
        "### Tipos de classificação\n",
        "\n",
        "É importante também olharmos para os tipos de classificação de produtos que a empresa tem. Na base fornecida, foram identificados 32 classes. É essencial entender que o modelo a ser treinado **não identificará classes de produtos que não estão na base de dados**. Desse modo, se a empresa quisesse identificar um produto como classe \"carro\" ou não, teria que acrescentar à base de dados vários produtos da categoria \"carro\".\n",
        "\n",
        "O modelo de machine learning não consegue interpretar dados do tipo string. Portanto, precisamos alterar os dados da coluna alvo `product_category`, fazendo uma tokerização simples, em outras palavras, substituindo as palavras por números. Os valores substituídos serão armazenados em uma coluna chamada `num_category`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iXiO-sYLaI2o"
      },
      "source": [
        "### execução das funções de tratamento do dataframe\n",
        "\n",
        "Todo esse tratamento descrito acima será feito por duas funções: `tratamento_reviews`, que tratará todo o conteúdo dos reviews dos clientes e `tratamento_categorias`, que tratará o conteúdo da coluna `product_category`. Enquanto que a primeira função retorna o dataframe acrescentado da coluna `review_total` (coluna esta que é criada pela próppria função), a segunda função reotornará o dataframe com os dados preparados para ser desenvolvido o modelo. Esse dataframe será chamado `df_ML` e conterá a coluna `review_total`, que será a variável x do modelo, e a coluna `num_category`, que será a variável y."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kTVAk4IABWjm"
      },
      "source": [
        "df_tratado = tratamento_reviews(df_tratado)\n",
        "df_ML = tratamento_categorias(df_tratado)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gMeQQhJstcf3"
      },
      "source": [
        "## Aplicação do machine learning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OrZ7Rhq4xyCg"
      },
      "source": [
        "### divisão dos dados em treino e teste / treinamento do modelo\n",
        "\n",
        "Após os tratamentos feitos, vamos separar os dados em treino e teste para o modelo. No entanto, mais uma transformação deverá ser feita na coluna `review_total`. Precisamos fazer a tokerização (ou vetorização) das palavras, além de transformar a coluna em uma matriz esparça, que é a entrada que o método `fit` do modelo `MultinomialNB` aceita. Para isso utilizaremos a classe `CountVectorizer` da biblioteca `sklearn`. Aqui, os dados da vetorização e da transformação em matriz esparça serão armazenados nas variáveis `X_train` e `X_test` (com X maiúsculo). A transformação será feita em cima de `x_train` e `x_test` (com x minúsculo), variáveis que serão preparadas através do método `train_test_split`, também da biblioteca `sklearn`. Estas variáveis são apenas uma separação dos dados de `df_ML`.\n",
        "\n",
        "Todo esse processo, bem como o treinamento do modelo, serão realizados pela função `treina_modelo`, que retornará o modelo treinado de Neive Beyes, bem como as matrizes esparças `X_train` e `X_test` e os arrays `y_train` e `y_test`. Além dessas variáveis, a função retornará também a instância `vect`, que será utilizada na função `validate` para tokerizar as palavras dos textos. Os parâmetros que esta função recebe são o dataframe (que deve ser tratado pelas duas funções de tratamento) e o número `seed`, que garante a reprodutibilidade do modelo. Aqui executaremos a função com seed = 50."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SLMjDh0B4Dz-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f1334fe3-3557-44fd-bafb-f9dd4c7a5361"
      },
      "source": [
        "X_train, X_test, y_train, y_test, mnb, vect = treina_modelo(df_ML, 50)\n",
        "\n",
        "result= mnb.predict(X_test)\n",
        "print(result)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2 2 3 ... 2 4 1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qjvCfq0itQ5Z"
      },
      "source": [
        "### validação do modelo\n",
        "\n",
        "Para validar o modelo, utilizaremos o proposto pelo desafio da Solvimm, que é calcular a acurácia. Isso será calculado através da biblioteca `sklearn`.\n",
        "\n",
        "O modelo desenvolvido aqui apresenta uma acurácia de aproximadamente 73,24%. Em outras palavras, com a divisão dos dados feitas aqui e com esse modelo treinado, estamos acertando praticamente a classificação de 3 a cada 4 produtos. Essa é uma acurácia maior do que o mínimo esperado no desafio."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dXHyItV15ju1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c4547f91-ee36-4436-8e83-02e636b1a7d6"
      },
      "source": [
        "accuracy_score(result,y_test)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7324250808985603"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yvi8pJKJu6U2"
      },
      "source": [
        "## Aplicando o modelo: função validate\n",
        "\n",
        "Por fim, após o tratamento, treinamento e validação do modelo, resta desenvolver uma função que aplique nosso modelo a um dataframe, afim de classificar os produtos nele contidos. Para isso, utilizaremos a função `validate`, que recebe o modelo treinado e um dataframe como o fornecido pela equipe da \"Ponto Quente\", mas sem a coluna `product_category`. A função deve retornar o mesmo dataframe de entrada, porém com a coluna `product_category` que terá as categorias previstas para cada produto.\n",
        "\n",
        "Não faz sentido nenhum executar esta função sobre a base de dados fornecida pela \"Ponto Quente\" para preparar o modelo, já que as classificações dos produtos já foram corrigidas pelo time da empresa. No entanto, utilizaremos a mesma base de dados apenas para verificar o funcionamento da função, uma vez que o modelo já está validado.\n",
        "\n",
        "É importante dizer que, antes de fazer de fato a predição do modelo, o dataframe que a função `validate` recebe precisa ser tratado, assim como fizemos o tratamento dos textos dos reviews antes de treinar o modelo. Mais especificamente, o dataframe precisa passar antes pela função `tratamento_reviews`, o que leva boa parte do tempo de execução de `validate`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hAw_KOv16F6k"
      },
      "source": [
        "df_teste = df_tratado.drop(['product_category', 'review_total'], axis=1)\n",
        "\n",
        "df_teste_tratado = tratamento_reviews(df_teste)       # tratando os textos de reviews"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 425
        },
        "id": "-S_R6bin-C90",
        "outputId": "f8e785fd-e044-49f0-abf1-ef1a62b420e6"
      },
      "source": [
        "df_sem_categoria = df_tratado.drop(['product_category', 'review_total'], axis=1)\n",
        "\n",
        "df_categorizado = validate(mnb, vect, df_sem_categoria)\n",
        "\n",
        "df_categorizado.head()"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>index</th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>marketplace</th>\n",
              "      <th>customer_id</th>\n",
              "      <th>review_id</th>\n",
              "      <th>product_id</th>\n",
              "      <th>product_parent</th>\n",
              "      <th>product_title</th>\n",
              "      <th>star_rating</th>\n",
              "      <th>helpful_votes</th>\n",
              "      <th>total_votes</th>\n",
              "      <th>vine</th>\n",
              "      <th>verified_purchase</th>\n",
              "      <th>review_headline</th>\n",
              "      <th>review_body</th>\n",
              "      <th>review_date</th>\n",
              "      <th>num_category</th>\n",
              "      <th>product_category</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>762868</td>\n",
              "      <td>UK</td>\n",
              "      <td>29723892</td>\n",
              "      <td>R3VNENIATVV8QE</td>\n",
              "      <td>B00NOPQU2K</td>\n",
              "      <td>627793267</td>\n",
              "      <td>The Girl on the Train</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>N</td>\n",
              "      <td>N</td>\n",
              "      <td>Gripping you right where it matters</td>\n",
              "      <td>I know to say a story is &amp;#34;gripping&amp;#34; is...</td>\n",
              "      <td>2015-04-27</td>\n",
              "      <td>0</td>\n",
              "      <td>Digital_Ebook_Purchase</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>1284183</td>\n",
              "      <td>UK</td>\n",
              "      <td>41072087</td>\n",
              "      <td>R2U3LV67N99770</td>\n",
              "      <td>B0013F2LSK</td>\n",
              "      <td>13214624</td>\n",
              "      <td>11</td>\n",
              "      <td>5</td>\n",
              "      <td>2</td>\n",
              "      <td>5</td>\n",
              "      <td>N</td>\n",
              "      <td>Y</td>\n",
              "      <td>The Best of Me</td>\n",
              "      <td>This album is totally fantastic, a great mix o...</td>\n",
              "      <td>2008-03-18</td>\n",
              "      <td>1</td>\n",
              "      <td>Music</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>1599315</td>\n",
              "      <td>UK</td>\n",
              "      <td>49938094</td>\n",
              "      <td>R3RO94POCHNI9V</td>\n",
              "      <td>B005CVWWJY</td>\n",
              "      <td>769273676</td>\n",
              "      <td>Ready Player One</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>N</td>\n",
              "      <td>Y</td>\n",
              "      <td>superb</td>\n",
              "      <td>Enjoyed every second of this book.  It took me...</td>\n",
              "      <td>2014-08-28</td>\n",
              "      <td>0</td>\n",
              "      <td>Digital_Ebook_Purchase</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>204782</td>\n",
              "      <td>UK</td>\n",
              "      <td>14398213</td>\n",
              "      <td>R3S2BB5SBWBC1</td>\n",
              "      <td>B00008AWV3</td>\n",
              "      <td>841759677</td>\n",
              "      <td>The Four Feathers [DVD] [1939]</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>N</td>\n",
              "      <td>Y</td>\n",
              "      <td>Sweeping, authentic historic drama</td>\n",
              "      <td>I loved the historic scenes---the English coun...</td>\n",
              "      <td>2013-12-27</td>\n",
              "      <td>2</td>\n",
              "      <td>Video DVD</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>352938</td>\n",
              "      <td>UK</td>\n",
              "      <td>20140500</td>\n",
              "      <td>R27E2PNXJSWJIN</td>\n",
              "      <td>B00FAXJHCY</td>\n",
              "      <td>803172158</td>\n",
              "      <td>The Martian</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>N</td>\n",
              "      <td>Y</td>\n",
              "      <td>... a few pages to get through it but a good b...</td>\n",
              "      <td>May have skipped a few pages to get through it...</td>\n",
              "      <td>2015-06-06</td>\n",
              "      <td>0</td>\n",
              "      <td>Digital_Ebook_Purchase</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   index  Unnamed: 0  ... num_category        product_category\n",
              "0      0      762868  ...            0  Digital_Ebook_Purchase\n",
              "1      1     1284183  ...            1                   Music\n",
              "2      2     1599315  ...            0  Digital_Ebook_Purchase\n",
              "3      3      204782  ...            2               Video DVD\n",
              "4      4      352938  ...            0  Digital_Ebook_Purchase\n",
              "\n",
              "[5 rows x 18 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    }
  ]
}